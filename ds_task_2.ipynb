{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaf70fcb-c753-4d1d-a47a-24cb63208eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2fa57e2-a2e7-4dbc-b486-944fc14f5763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the API key for OpenAI\n",
    "openai.api_key = \"openai-api\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a574deae-7923-4cb4-b098-cf326e3b44db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate a GPT-3 prompt based on client answers\n",
    "def generate_prompt(answers):\n",
    "    prompt = \"Given the following rules:\\n\\n\"\n",
    "    prompt += \"1. If you go out to party on weekends, you are allowed to choose from apples, pears, grapes, and watermelon.\\n\"\n",
    "    prompt += \"2. If you like cider, you can choose from apples, oranges, lemon, and lime.\\n\"\n",
    "    prompt += \"3. If you like sweet flavors, you can choose from watermelon and oranges.\\n\"\n",
    "    prompt += \"4. If you like waterlike drinks, you can choose watermelon.\\n\"\n",
    "    prompt += \"5. If grapes are chosen, watermelon is removed from the list.\\n\"\n",
    "    prompt += \"6. If you don't like smooth texture, pears are removed.\\n\"\n",
    "    prompt += \"7. If you don't like slimy texture, watermelon, lime, and grapes are removed.\\n\"\n",
    "    prompt += \"8. If you don't like waterlike texture, watermelon is removed.\\n\"\n",
    "    prompt += \"9. If the price is less than $3, lime and watermelon are removed.\\n\"\n",
    "    prompt += \"10. If the price is between $4 and $7, pears and apples are removed.\\n\\n\"\n",
    "    prompt += \"Based on your answers, here are the recommended fruits:\\n\"\n",
    "\n",
    "    # Determine which fruits are allowed based on the answers\n",
    "    allowed_fruits = []\n",
    "    if answers[\"weekend_party\"] == \"yes\":\n",
    "        allowed_fruits.extend([\"apples\", \"pears\", \"grapes\", \"watermelon\"])\n",
    "    if answers[\"flavor\"] == \"cider\":\n",
    "        allowed_fruits.extend([\"apples\", \"oranges\", \"lemon\", \"lime\"])\n",
    "    elif answers[\"flavor\"] == \"sweet\":\n",
    "        allowed_fruits.extend([\"watermelon\", \"oranges\"])\n",
    "    elif answers[\"flavor\"] == \"waterlike\":\n",
    "        allowed_fruits.append(\"watermelon\")\n",
    "\n",
    "    # Handle removal of fruits based on texture preference\n",
    "    if answers[\"texture\"] == \"smooth\":\n",
    "        allowed_fruits = [fruit for fruit in allowed_fruits if fruit != \"pears\"]\n",
    "    elif answers[\"texture\"] == \"slimy\":\n",
    "        allowed_fruits = [fruit for fruit in allowed_fruits if fruit not in [\"watermelon\", \"lime\", \"grapes\"]]\n",
    "    elif answers[\"texture\"] == \"waterlike\":\n",
    "        allowed_fruits = [fruit for fruit in allowed_fruits if fruit != \"watermelon\"]\n",
    "\n",
    "    # Handle removal of fruits based on price range\n",
    "    price_range = answers[\"price\"]\n",
    "    if price_range < 3:\n",
    "        allowed_fruits = [fruit for fruit in allowed_fruits if fruit not in [\"lime\", \"watermelon\"]]\n",
    "    elif 4 <= price_range <= 7:\n",
    "        allowed_fruits = [fruit for fruit in allowed_fruits if fruit not in [\"pears\", \"apples\"]]\n",
    "\n",
    "    prompt += \", \".join(allowed_fruits)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb52ddfa-f9a0-4c25-a6e5-fa877eac0cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/recommend_fruits', methods=['POST'])\n",
    "def recommend_fruits():\n",
    "    data = request.get_json()\n",
    "    answers = data[\"answers\"]\n",
    "    prompt = generate_prompt(answers)\n",
    "\n",
    "    # Generate an answer using GPT-3\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=150\n",
    "    )\n",
    "\n",
    "    # Extract the generated text from the response\n",
    "    recommended_fruits = response.choices[0].message['content'].strip()\n",
    "\n",
    "    return jsonify({\"recommended_fruits\": recommended_fruits})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b334ce4-d8b4-4513-a2e7-cedaaf6b4a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      " * Restarting with stat\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michael.A_Sydani\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94ce0ed-453b-4696-832c-6cb7668c5f08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
